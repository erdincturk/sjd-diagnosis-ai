{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate CAM images for all test data. \n",
    "Before running this code copy the training files of the best/selected model (namded as \"sgkf05-yolo11s\") to 'classify-bestmodel' folder under runs file. If this file doesn't exist create one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT PACKAGES\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "from pytorch_grad_cam import (\n",
    "    GradCAM, FEM, HiResCAM, ScoreCAM, GradCAMPlusPlus,\n",
    "    AblationCAM, XGradCAM, EigenCAM, EigenGradCAM,\n",
    "    LayerCAM, FullGrad, GradCAMElementWise, KPCA_CAM, ShapleyCAM,\n",
    "    FinerCAM\n",
    ")\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image, preprocess_image\n",
    "import torch\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    return [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith(('.jpg', '.png'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_yaml_config(yaml_path, keys_to_extract):\n",
    "    if not os.path.exists(yaml_path):\n",
    "        return {key: None for key in keys_to_extract}\n",
    "    with open(yaml_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    return {key: config.get(key, None) for key in keys_to_extract}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION\n",
    "classes = ['NRM', 'PSS']\n",
    "\n",
    "data_dir = os.path.join('data', '2-splits')\n",
    "seeds = [f'seed{r:02}' for r in range(1, 6)]\n",
    "fold_counts = {'sgkf05': 5}\n",
    "\n",
    "base_run_dir = os.path.join('runs', 'classify-bestmodel')\n",
    "sgkf='sgkf05'\n",
    "model_name = 'yolo11s'\n",
    "model_base = f'{sgkf}-{model_name}'\n",
    "\n",
    "# YAML fields to log from training\n",
    "yaml_keys = [\n",
    "    'epochs', 'batch', 'imgsz', 'optimizer', 'dropout', 'lr0',\n",
    "    'weight_decay', 'model', 'pretrained', 'single_cls',\n",
    "    'auto_augment', 'data'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model interpretation\n",
    "results = []\n",
    "\n",
    "for seed in seeds:\n",
    "    fold_range = range(1, fold_counts[sgkf] + 1)\n",
    "\n",
    "    for fold in fold_range:\n",
    "\n",
    "        fold_name = f'fold{fold:02}'\n",
    "        train_id = f'train-{seed}-{fold_name}'\n",
    "        test_id = f'test-{seed}-{fold_name}'\n",
    "\n",
    "        data_test_dir = os.path.join(data_dir, sgkf, seed, fold_name, 'test')\n",
    "\n",
    "        # Paths\n",
    "        model_path = os.path.join(base_run_dir, model_base, train_id, 'weights', 'best.pt')\n",
    "        yaml_path  = os.path.join(base_run_dir, model_base, train_id, 'args.yaml')\n",
    "        data_test_dir   = os.path.join(data_dir, sgkf, seed, fold_name, 'test')\n",
    "\n",
    "        # Skip if any key file is missing\n",
    "        if not os.path.exists(model_path) or not os.path.exists(data_test_dir) or not os.path.exists(yaml_path):\n",
    "            print(f\"‚ö†Ô∏è Skipping (missing): {model_path} or {data_test_dir} or {yaml_path}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nüìå Evaluating: {model_base} | {seed} | {fold_name}\")\n",
    "        model = YOLO(model_path)\n",
    "        true_labels = []\n",
    "        predicted_labels = []\n",
    "\n",
    "        # Grad-CAM setup        \n",
    "        gradcam_model = 'EigenGradCAM'      # 'GradCAM', 'GradCAMPlusPlus', 'EigenGradCAM', 'LayerCAM', 'HiResCAM', 'FinerCAM'\n",
    "        \n",
    "        gradcam_dir = os.path.join(base_run_dir, model_base, test_id, f'{gradcam_model}')\n",
    "        os.makedirs(gradcam_dir, exist_ok=True)\n",
    "        gradcam_image_dir = os.path.join(gradcam_dir, 'images')\n",
    "        os.makedirs(gradcam_image_dir, exist_ok=True)\n",
    "        gradcam_combined_dir = os.path.join(gradcam_dir, 'combined')        \n",
    "        os.makedirs(gradcam_combined_dir, exist_ok=True)\n",
    "    \n",
    "        image_logs = []\n",
    "\n",
    "        for cls_index, cls in enumerate(classes):\n",
    "            cls_dir = os.path.normpath(os.path.join(data_test_dir, cls))\n",
    "            images = load_images_from_folder(cls_dir)\n",
    "            \n",
    "            for img_path in tqdm(images, desc=f'{cls} images'):\n",
    "\n",
    "                results_pred = model(img_path)\n",
    "                predicted_class = results_pred[0].probs.top1\n",
    "                true_labels.append(cls_index)\n",
    "\n",
    "                # Log per-image inference\n",
    "                image_logs.append({\n",
    "                    'image_path': img_path,\n",
    "                    'true_label': cls,\n",
    "                    'predicted_label': classes[predicted_class],\n",
    "                    'correct': int(cls_index == predicted_class)\n",
    "                })\n",
    "\n",
    "                predicted_labels.append(predicted_class)\n",
    "\n",
    "                # Get inner PyTorch model\n",
    "                cam_model = model.model\n",
    "                # Set the correct last convolutional layer as target \n",
    "                target_layers = [cam_model.model[10].conv.conv]\n",
    "                \n",
    "                # Read and preprocess image\n",
    "                img = cv2.imread(img_path)\n",
    "                img = cv2.resize(img, (224, 224))\n",
    "                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img_float = img_rgb.astype(np.float32) / 255.0\n",
    "\n",
    "                device = next(cam_model.parameters()).device\n",
    "                \n",
    "                # Create tensor                      \n",
    "                input_tensor = preprocess_image(img_rgb, mean=[0, 0, 0], std=[1, 1, 1]).to(device)\n",
    "                input_tensor.requires_grad_(True)\n",
    "                \n",
    "                logits = cam_model(input_tensor)[0]\n",
    "                pred_class = logits.argmax().item()\n",
    "\n",
    "                # Apply GradCAM\n",
    "                targets = [ClassifierOutputTarget(pred_class)]      \n",
    "                #print(targets)\n",
    "                \n",
    "                # Create GradCAM object\n",
    "                if gradcam_model == 'GradCAM':\n",
    "                    cam = GradCAM(model=cam_model, target_layers=target_layers)\n",
    "                elif gradcam_model == 'GradCAMPlusPlus':\n",
    "                    cam = GradCAMPlusPlus(model=cam_model, target_layers=target_layers)\n",
    "                elif gradcam_model == 'EigenGradCAM':\n",
    "                    cam = EigenGradCAM(model=cam_model, target_layers=target_layers)                          \n",
    "                elif gradcam_model == 'LayerCAM':\n",
    "                    cam = LayerCAM(model=cam_model, target_layers=target_layers)\n",
    "                elif gradcam_model == 'HiResCAM':\n",
    "                    cam = HiResCAM(model=cam_model, target_layers=target_layers)\n",
    "                elif gradcam_model == 'FinerCAM':\n",
    "                    cam = FinerCAM(model=cam_model, target_layers=target_layers)\n",
    "\n",
    "                grayscale_cam = cam(input_tensor=input_tensor, targets=targets)[0, :]      \n",
    "                    \n",
    "                cam_overlay = show_cam_on_image(img_float, grayscale_cam, use_rgb=True)\n",
    "\n",
    "                base_filename = os.path.splitext(os.path.basename(img_path))[0]\n",
    "\n",
    "                # Save Grad-CAM image\n",
    "                gradcam_image_path = os.path.join(gradcam_image_dir, f'{base_filename}_{classes[pred_class]}_gradcam.jpg')\n",
    "                cv2.imwrite(gradcam_image_path, cv2.cvtColor(cam_overlay, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "                # Save combined side-by-side figure (original | grad-cam)\n",
    "                fig, axes = plt.subplots(1, 2, figsize=(6, 3), dpi=300)\n",
    "                \n",
    "                # Define font style\n",
    "                font_settings = {\n",
    "                    'family': 'Times New Roman',\n",
    "                    'size': 10\n",
    "                }\n",
    "                \n",
    "                # Left: Original\n",
    "                axes[0].imshow(img_rgb)\n",
    "                axes[0].set_title(\"Original\", fontdict=font_settings, pad=10)\n",
    "                axes[0].axis(\"off\")\n",
    "\n",
    "                # Right: Grad-CAM\n",
    "                axes[1].imshow(cam_overlay)\n",
    "                axes[1].set_title(f\"{gradcam_model}\", fontdict=font_settings, pad=10)\n",
    "                axes[1].axis(\"off\")\n",
    "\n",
    "                # Save\n",
    "                predicted_cls_name = classes[predicted_class]\n",
    "                combined_fig_path = os.path.join(gradcam_combined_dir, f'{base_filename}_{predicted_cls_name}_combined.jpg')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(combined_fig_path, bbox_inches='tight', dpi=300)\n",
    "                plt.close(fig)    \n",
    "        \n",
    "\n",
    "\n",
    "        # Save per-image predictions\n",
    "        image_log_df = pd.DataFrame(image_logs)\n",
    "        image_log_path = os.path.join(base_run_dir, model_base, test_id, 'image_predictions.csv')\n",
    "        image_log_df.to_csv(image_log_path, index=False)\n",
    "        print(f\"üìù Per-image log saved to: {image_log_path}\")\n",
    "\n",
    "        # Confusion matrix\n",
    "        cm = confusion_matrix(true_labels, predicted_labels, labels=[0, 1])\n",
    "\n",
    "        # Create subfolder for confusion matrix output\n",
    "        cm_output_dir = os.path.join(base_run_dir, model_base, test_id)\n",
    "        os.makedirs(cm_output_dir, exist_ok=True)\n",
    "        cm_fig_path = os.path.join(cm_output_dir, 'confusion_matrix.png')\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "        disp.plot(cmap='Blues', ax=ax)\n",
    "        plt.title(f\"Confusion Matrix-{model_base}-{seed}-{fold_name}\")\n",
    "        plt.savefig(cm_fig_path)\n",
    "        plt.close(fig)\n",
    "        print(f\"‚úÖ Confusion matrix saved to: {cm_fig_path}\")\n",
    "\n",
    "        TP, TN, FP, FN = cm[1, 1], cm[0, 0], cm[0, 1], cm[1, 0]\n",
    "\n",
    "        # Metrics\n",
    "        accuracy = round((TP + TN) / np.sum(cm), 4)\n",
    "        precision = round(TP / (TP + FP), 4) if (TP + FP) else 0.0\n",
    "        sensitivity = round(TP / (TP + FN), 4) if (TP + FN) else 0.0\n",
    "        specificity = round(TN / (TN + FP), 4) if (TN + FP) else 0.0\n",
    "        f1_score = round(2 * (precision * sensitivity) / (precision + sensitivity), 4) if (precision + sensitivity) else 0.0\n",
    "\n",
    "        # Load training configuration from YAML\n",
    "        config_data = load_yaml_config(yaml_path, yaml_keys)\n",
    "        expected_data_path = os.path.join(data_dir, sgkf, seed, fold_name)\n",
    "        yaml_data_path = config_data.pop('data', '')\n",
    "        config_data['data_path_match'] = expected_data_path in yaml_data_path\n",
    "\n",
    "        # Append full record\n",
    "        results.append({\n",
    "            'sgkf': sgkf,\n",
    "            'yolo_version': model_name,\n",
    "            'seed': seed,\n",
    "            'fold': fold_name,\n",
    "            'TP': TP,\n",
    "            'TN': TN,\n",
    "            'FP': FP,\n",
    "            'FN': FN,\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'sensitivity': sensitivity,\n",
    "            'specificity': specificity,\n",
    "            'f1_score': f1_score,\n",
    "            **config_data\n",
    "        })\n",
    "# Save CSV with descriptive name\n",
    "csv_name = f\"test-{sgkf}-{model_name}.csv\"\n",
    "output_path = os.path.join(base_run_dir, model_base, csv_name)\n",
    "df = pd.DataFrame(results)\n",
    "drop_columns = ['auto_augment']\n",
    "df.drop(columns=[col for col in drop_columns if col in df.columns], inplace=True)\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"\\nüìÜ Output saved to: {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
