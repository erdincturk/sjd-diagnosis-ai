{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive ROI Localization and Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT PACKAGES\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Configurable Parameters ===\n",
    "THRESHOLD = 50\n",
    "\n",
    "RESIZE_DIMS = (640, 640)\n",
    "\n",
    "DEBUG = True  # Set True to save visualizations\n",
    "LOG_PATH = f\"temp/preprocessing/preprocessing_log.csv\"\n",
    "DEBUG_DIR = \"temp/preprocessing/image-crops\"\n",
    "os.makedirs(DEBUG_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUM PIXEL VALUES VERTICALLY\n",
    "def vertical_sum(image):        \n",
    "    return np.count_nonzero(image, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUM PIXEL VALUES HORIZONTALLY\n",
    "def horizontal_sum(image):        \n",
    "    return np.count_nonzero(image > 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIND EXTREME CHANGES\n",
    "def find_extreme_changes(array, threshold=THRESHOLD):\n",
    "    # Calculate the first derivative\n",
    "    derivative = np.diff(array)\n",
    "    # Find points where the derivative exceeds the threshold\n",
    "    increases = np.where(derivative > threshold)[0]\n",
    "    decreases = np.where(derivative < -threshold)[0]\n",
    "    return increases, decreases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CROP IMAGE\n",
    "def crop_image_with_padding(image, x1, x2, y1, y2):\n",
    "    h, w, c = image.shape\n",
    "    crop_w = x2 - x1\n",
    "    crop_h = y2 - y1\n",
    "    cropped = np.zeros((crop_h, crop_w, c), dtype=np.uint8)\n",
    "\n",
    "    x1_clamped = max(0, x1)\n",
    "    y1_clamped = max(0, y1)\n",
    "    x2_clamped = min(w, x2)\n",
    "    y2_clamped = min(h, y2)\n",
    "\n",
    "    insert_x1 = x1_clamped - x1\n",
    "    insert_y1 = y1_clamped - y1\n",
    "\n",
    "    crop = image[y1_clamped:y2_clamped, x1_clamped:x2_clamped]\n",
    "    cropped[insert_y1:insert_y1 + crop.shape[0], insert_x1:insert_x1 + crop.shape[1]] = crop\n",
    "    return cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Main Processing Function ===\n",
    "def process_images(root_dir):\n",
    "    data_processed_dir = os.path.join(root_dir, '..', f'1-processed')\n",
    "    os.makedirs(data_processed_dir, exist_ok=True)\n",
    "\n",
    "    with open(LOG_PATH, \"w\", newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([\"image_path\", \"roi_x1\", \"roi_x2\", \"roi_y1\", \"roi_y2\", \"roi_aspect_ratio\", \"status\"])\n",
    "\n",
    "        for class_dir in os.listdir(root_dir):\n",
    "            class_path = os.path.join(root_dir, class_dir)\n",
    "            \n",
    "            if not os.path.isdir(class_path):\n",
    "                continue\n",
    "\n",
    "            for patient_dir in os.listdir(class_path):\n",
    "                patient_path = os.path.join(class_path, patient_dir)\n",
    "                \n",
    "                if not os.path.isdir(patient_path):\n",
    "                    continue\n",
    "\n",
    "                for image_file in os.listdir(patient_path):\n",
    "                    image_path = os.path.join(patient_path, image_file)\n",
    "                    \n",
    "                    if not image_file.endswith('.jpg'):\n",
    "                        continue\n",
    "\n",
    "                    # Read the image    \n",
    "                    print(f\"Processing {image_path}\")\n",
    "                    image = cv2.imread(image_path)\n",
    "                    if image is None:\n",
    "                        print(f\"Warning: Unable to read {image_path}\")\n",
    "                        writer.writerow([image_path, None, None, None, None, None, \"failed to read\"])\n",
    "                        continue\n",
    "\n",
    "                    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                    \n",
    "                    # Calculate the vertical and horizontal sums\n",
    "                    vertical_sums = vertical_sum(image_gray)\n",
    "                    horizontal_sums = horizontal_sum(image_gray)\n",
    "\n",
    "                    # Find the extreme changes in the vertical and horizontal sums\n",
    "                    v_inc, v_dec = find_extreme_changes(vertical_sums)\n",
    "                    h_inc, h_dec = find_extreme_changes(horizontal_sums)\n",
    "\n",
    "                    if len(v_inc) < 2 or len(v_dec) < 2 or len(h_inc) == 0:\n",
    "                        print(f\"Skipping {image_path} due to insufficient edges\")\n",
    "                        writer.writerow([image_path, None, None, None, None, None, \"insufficient edges\"])\n",
    "                        continue\n",
    "\n",
    "                    roi_x1 = int(v_inc[1]) + 1\n",
    "                    roi_x2 = int(v_dec[1])\n",
    "                    roi_y1 = int(h_inc[0] - (roi_x2 - roi_x1) * 0.09)\n",
    "                    roi_y2 = int((roi_x2 - roi_x1) + roi_y1)\n",
    "                    roi_width = roi_x2 - roi_x1\n",
    "                    roi_height = roi_y2 - roi_y1\n",
    "                    roi_aspect_ratio = round(roi_width / roi_height, 4) if roi_height != 0 else None\n",
    "\n",
    "                    image_cropped = crop_image_with_padding(image, roi_x1, roi_x2, roi_y1, roi_y2)\n",
    "                    image_resized = cv2.resize(image_cropped, RESIZE_DIMS)\n",
    "\n",
    "                    new_patient_dir = os.path.join(data_processed_dir, class_dir, patient_dir)\n",
    "                    os.makedirs(new_patient_dir, exist_ok=True)\n",
    "                    processed_path = os.path.join(new_patient_dir, image_file)\n",
    "                    cv2.imwrite(processed_path, image_resized)\n",
    "\n",
    "                    writer.writerow([image_path, roi_x1, roi_x2, roi_y1, roi_y2, roi_aspect_ratio, \"processed\"])\n",
    "                    print(f\"Saved: {processed_path}\")\n",
    "\n",
    "                    # Optional: Debug visualization\n",
    "                    if DEBUG:\n",
    "                        vis = image.copy()\n",
    "                        cv2.rectangle(vis, (roi_x1, roi_y1), (roi_x2, roi_y2), (255, 0, 0), 2)\n",
    "                        plt.imshow(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB))\n",
    "                        plt.title(image_file)\n",
    "                        plt.savefig(os.path.join(DEBUG_DIR, image_file.replace('.jpg', '_debug.png')))\n",
    "                        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run preprocessing\n",
    "current_dir = os.getcwd()\n",
    "print(\"Current Directory: \", current_dir)\n",
    "print(\"Files: \", os.listdir(current_dir))\n",
    "\n",
    "data_raw_dir = os.path.join('data', '0-raw')\n",
    "process_images(data_raw_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
