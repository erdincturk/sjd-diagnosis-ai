{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "DATASET_DIR = \"data/1-processed/\"\n",
    "OUTPUT_BASE_DIR = \"data/2-splits/\"\n",
    "CSV_OUTPUT_PATH = os.path.join(OUTPUT_BASE_DIR, \"sgkf05\", \"split_summary.csv\")\n",
    "\n",
    "# Settings for 5-fold CV\n",
    "CONFIGS = {\n",
    "    \"sgkf05\": dict(n_seeds=5, n_splits=5)\n",
    "}\n",
    "\n",
    "# Recommended seeds\n",
    "SEED_LIST = [0, 42, 77, 123, 2025]\n",
    "\n",
    "# Class labels\n",
    "class_map = {\"NRM\": 0, \"SJD\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect participant data\n",
    "groups, labels, file_paths = [], [], []\n",
    "\n",
    "print(\"Collecting dataset...\")\n",
    "for class_name in [\"NRM\", \"SJD\"]:\n",
    "    class_dir = os.path.join(DATASET_DIR, class_name)\n",
    "    if not os.path.exists(class_dir):\n",
    "        continue\n",
    "    for participant in os.listdir(class_dir):\n",
    "        participant_path = os.path.join(class_dir, participant)\n",
    "        if os.path.isdir(participant_path):\n",
    "            label = class_map[class_name]\n",
    "            for image_file in os.listdir(participant_path):\n",
    "                if image_file.endswith(\".jpg\"):\n",
    "                    image_path = os.path.join(participant_path, image_file)\n",
    "                    file_paths.append(image_path)\n",
    "                    labels.append(label)\n",
    "                    groups.append(participant)\n",
    "\n",
    "file_paths = np.array(file_paths)\n",
    "labels = np.array(labels)\n",
    "groups = np.array(groups)\n",
    "\n",
    "summary_records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform splitting for each config\n",
    "for config_name, cfg in CONFIGS.items():\n",
    "    n_seeds = cfg[\"n_seeds\"]\n",
    "    n_splits = cfg[\"n_splits\"]\n",
    "\n",
    "    for seed_idx in range(1, n_seeds + 1):\n",
    "        seed = SEED_LIST[seed_idx - 1] if seed_idx - 1 < len(SEED_LIST) else seed_idx\n",
    "        sgkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "        for fold_idx, (train_val_idx, test_idx) in enumerate(sgkf.split(file_paths, labels, groups), start=1):\n",
    "            train_val_files = file_paths[train_val_idx]\n",
    "            train_val_labels = labels[train_val_idx]\n",
    "            train_val_groups = groups[train_val_idx]\n",
    "\n",
    "            inner_sgkf = StratifiedGroupKFold(n_splits=4, shuffle=True, random_state=seed + 99)\n",
    "            train_idx, val_idx = next(inner_sgkf.split(train_val_files, train_val_labels, train_val_groups))\n",
    "\n",
    "            train_idx = train_val_idx[train_idx]\n",
    "            val_idx = train_val_idx[val_idx]\n",
    "\n",
    "            fold_path = os.path.join(OUTPUT_BASE_DIR, config_name, f\"seed{seed_idx:02d}\", f\"fold{fold_idx:02d}\")\n",
    "            os.makedirs(fold_path, exist_ok=True)\n",
    "\n",
    "            split_dict = {\"train\": train_idx, \"val\": val_idx, \"test\": test_idx}\n",
    "\n",
    "            # Ensure no subject overlap\n",
    "            participant_sets = {\n",
    "                split: set(groups[idx] for idx in indices) for split, indices in split_dict.items()\n",
    "            }\n",
    "            assert len(participant_sets[\"train\"] & participant_sets[\"val\"]) == 0, \"Overlap between train and val!\"\n",
    "            assert len(participant_sets[\"train\"] & participant_sets[\"test\"]) == 0, \"Overlap between train and test!\"\n",
    "            assert len(participant_sets[\"val\"] & participant_sets[\"test\"]) == 0, \"Overlap between val and test!\"\n",
    "\n",
    "            image_counts = {split: len(indices) for split, indices in split_dict.items()}\n",
    "            total_participants = sum(len(s) for s in participant_sets.values())\n",
    "\n",
    "            print(f\"[{config_name}] Seed {seed_idx:02d} - Fold {fold_idx:02d}:\")\n",
    "            for split in [\"train\", \"val\", \"test\"]:\n",
    "                indices = split_dict[split]\n",
    "                n_images = image_counts[split]\n",
    "                n_participants = len(participant_sets[split])\n",
    "                pct = (n_participants / total_participants) * 100\n",
    "\n",
    "                split_labels = labels[indices]\n",
    "                n_nrm = np.sum(split_labels == class_map[\"NRM\"])\n",
    "                n_sjd = np.sum(split_labels == class_map[\"SJD\"])\n",
    "\n",
    "                print(f\"  {split.capitalize()}: {n_images} images, {n_participants} participants \"\n",
    "                      f\"({pct:.2f}%) [NRM: {n_nrm}, sjd: {n_sjd}]\")\n",
    "\n",
    "                summary_records.append({\n",
    "                    \"config\": config_name,\n",
    "                    \"seed\": f\"seed{seed_idx:02d}\",\n",
    "                    \"fold\": f\"fold{fold_idx:02d}\",\n",
    "                    \"split\": split,\n",
    "                    \"n_images\": n_images,\n",
    "                    \"n_participants\": n_participants,\n",
    "                    \"pct_participants\": round(pct, 2),\n",
    "                    \"n_nrm\": int(n_nrm),\n",
    "                    \"n_sjd\": int(n_sjd)\n",
    "                })\n",
    "\n",
    "            # Copy files to corresponding folders\n",
    "            for split, indices in split_dict.items():\n",
    "                split_dir = os.path.join(fold_path, split)\n",
    "                os.makedirs(split_dir, exist_ok=True)\n",
    "                for idx in indices:\n",
    "                    src_path = file_paths[idx]\n",
    "                    group_label = groups[idx].split(\"-\")[0]  # NRM or SJD\n",
    "                    dest_dir = os.path.join(split_dir, group_label)\n",
    "                    os.makedirs(dest_dir, exist_ok=True)\n",
    "                    shutil.copy(src_path, os.path.join(dest_dir, os.path.basename(src_path)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save summary CSV\n",
    "summary_df = pd.DataFrame(summary_records)\n",
    "os.makedirs(os.path.dirname(CSV_OUTPUT_PATH), exist_ok=True)\n",
    "summary_df.to_csv(CSV_OUTPUT_PATH, index=False)\n",
    "print(f\"\\nâœ… All dataset splits created successfully!\")\n",
    "print(f\"ðŸ“„ Summary CSV saved to: {CSV_OUTPUT_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
