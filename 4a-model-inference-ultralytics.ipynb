{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# IMPORT PACKAGES\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve, auc, RocCurveDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    exts = ('.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff')\n",
    "    return [os.path.join(folder, f) for f in os.listdir(folder) if f.lower().endswith(exts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_yaml_config(yaml_path, keys_to_extract):\n",
    "    if not os.path.exists(yaml_path):\n",
    "        return {key: None for key in keys_to_extract}\n",
    "    with open(yaml_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    return {key: config.get(key, None) for key in keys_to_extract}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION\n",
    "base_run_dir = os.path.join('runs', 'classify')\n",
    "data_base = os.path.join('data', '2-splits')\n",
    "classes = ['NRM', 'PSS']  # negative, positive (PSS is treated as positive class for ROC)\n",
    "POS_CLASS_INDEX = classes.index('PSS')\n",
    "\n",
    "sgkf_versions = ['sgkf05']\n",
    "yolo_versions = ['yolo11s']\n",
    "seeds = [f'seed{r:02}' for r in range(1, 6)]\n",
    "fold_counts = {'sgkf05': 5, 'sgkf10': 10}\n",
    "\n",
    "# YAML fields to log from training\n",
    "yaml_keys = [\n",
    "    'epochs', 'batch', 'imgsz', 'optimizer', 'dropout', 'lr0',\n",
    "    'weight_decay', 'model', 'pretrained', 'single_cls',\n",
    "    'auto_augment', 'data'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sgkf in sgkf_versions:\n",
    "    for yolo in yolo_versions:\n",
    "        model_base = f'{sgkf}-{yolo}'\n",
    "        results = []\n",
    "\n",
    "        for seed in seeds:\n",
    "            fold_range = range(1, fold_counts[sgkf] + 1)\n",
    "\n",
    "            for fold in fold_range:\n",
    "                fold_name = f'fold{fold:02}'\n",
    "                train_id = f'train-{seed}-{fold_name}'\n",
    "\n",
    "                # Paths\n",
    "                model_path = os.path.join(base_run_dir, model_base, train_id, 'weights', 'best.pt')\n",
    "                yaml_path  = os.path.join(base_run_dir, model_base, train_id, 'args.yaml')\n",
    "                test_dir   = os.path.join(data_base, sgkf, seed, fold_name, 'test')\n",
    "\n",
    "                # Skip if any key file is missing\n",
    "                if not (os.path.exists(model_path) and os.path.exists(test_dir) and os.path.exists(yaml_path)):\n",
    "                    print(f\"‚ö†Ô∏è Skipping (missing): {model_path} or {test_dir} or {yaml_path}\")\n",
    "                    continue\n",
    "\n",
    "                print(f\"\\nüìå Evaluating: {model_base} | {seed} | {fold_name}\")\n",
    "                model = YOLO(model_path)\n",
    "\n",
    "                # Collect labels, predicted labels, and scores for ROC\n",
    "                true_labels = []\n",
    "                predicted_labels = []\n",
    "                pos_scores = []          # probability/score for positive class (PSS)\n",
    "                file_ids = []            # optional: keep image names for per-image CSV\n",
    "\n",
    "                for cls_index, cls in enumerate(classes):\n",
    "                    cls_dir = os.path.normpath(os.path.join(test_dir, cls))\n",
    "                    images = load_images_from_folder(cls_dir)\n",
    "                    for img_path in tqdm(images, desc=f'{cls} images'):\n",
    "                        pred = model(img_path, verbose=False)[0]\n",
    "                        # top-1 predicted class for confusion matrix\n",
    "                        top1 = int(pred.probs.top1)\n",
    "                        # probability for positive class (PSS)\n",
    "                        # pred.probs.data is a torch tensor with per-class softmax scores\n",
    "                        score_pos = float(pred.probs.data[POS_CLASS_INDEX].item())\n",
    "\n",
    "                        true_labels.append(cls_index)\n",
    "                        predicted_labels.append(top1)\n",
    "                        pos_scores.append(score_pos)\n",
    "                        file_ids.append(os.path.basename(img_path))\n",
    "\n",
    "                # Ensure arrays\n",
    "                y_true = np.array(true_labels, dtype=int)\n",
    "                y_pred = np.array(predicted_labels, dtype=int)\n",
    "                y_score = np.array(pos_scores, dtype=float)\n",
    "\n",
    "                # --- Confusion matrix (from top-1, i.e., argmax rule) ---\n",
    "                cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "\n",
    "                # Create subfolder for outputs\n",
    "                out_dir = os.path.join(base_run_dir, model_base, f'test-{seed}-{fold_name}')\n",
    "                os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "                # Save confusion matrix PNG\n",
    "                cm_fig_path = os.path.join(out_dir, 'confusion_matrix.png')\n",
    "                fig_cm, ax_cm = plt.subplots()\n",
    "                disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "                disp.plot(cmap='Blues', ax=ax_cm, colorbar=False)\n",
    "                ax_cm.set_title(f\"Confusion Matrix ‚Äî {model_base} ‚Äî {seed} ‚Äî {fold_name}\")\n",
    "                fig_cm.tight_layout()\n",
    "                fig_cm.savefig(cm_fig_path, dpi=300)\n",
    "                plt.close(fig_cm)\n",
    "                print(f\"‚úÖ Confusion matrix saved to: {cm_fig_path}\")\n",
    "\n",
    "                # --- ROC curve & AUC (threshold-free) ---\n",
    "                fpr, tpr, thresholds = roc_curve(y_true, y_score, pos_label=POS_CLASS_INDEX)\n",
    "                roc_auc = auc(fpr, tpr)\n",
    "\n",
    "                # Save ROC PNG\n",
    "                roc_fig_path = os.path.join(out_dir, 'roc_curve.png')\n",
    "                fig_roc, ax_roc = plt.subplots()\n",
    "                RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name=f'{model_base}-{seed}-{fold_name}').plot(ax=ax_roc)\n",
    "                ax_roc.set_title(f\"ROC ‚Äî {model_base} ‚Äî {seed} ‚Äî {fold_name} (AUC={roc_auc:.3f})\")\n",
    "                ax_roc.grid(True, linestyle='--', alpha=0.4)\n",
    "                fig_roc.tight_layout()\n",
    "                fig_roc.savefig(roc_fig_path, dpi=300)\n",
    "                plt.close(fig_roc)\n",
    "                print(f\"‚úÖ ROC curve saved to: {roc_fig_path}\")\n",
    "\n",
    "                # Save ROC points (CSV)\n",
    "                roc_csv_path = os.path.join(out_dir, 'roc_points.csv')\n",
    "                pd.DataFrame({'threshold': thresholds, 'fpr': fpr, 'tpr': tpr}).to_csv(roc_csv_path, index=False)\n",
    "                print(f\"‚úÖ ROC points saved to: {roc_csv_path}\")\n",
    "\n",
    "                # Optional: per-image predictions & scores\n",
    "                per_img_csv = os.path.join(out_dir, 'per_image_predictions.csv')\n",
    "                pd.DataFrame({\n",
    "                    'image': file_ids,\n",
    "                    'true_label': y_true,\n",
    "                    'pred_label': y_pred,\n",
    "                    'score_pos_PSS': y_score\n",
    "                }).to_csv(per_img_csv, index=False)\n",
    "\n",
    "                # Confusion-matrix-based metrics (argmax decision)\n",
    "                TP, TN, FP, FN = cm[1, 1], cm[0, 0], cm[0, 1], cm[1, 0]\n",
    "                accuracy = round((TP + TN) / np.sum(cm), 4)\n",
    "                precision = round(TP / (TP + FP), 4) if (TP + FP) else 0.0\n",
    "                sensitivity = round(TP / (TP + FN), 4) if (TP + FN) else 0.0\n",
    "                specificity = round(TN / (TN + FP), 4) if (TN + FP) else 0.0\n",
    "                f1_score = round(2 * (precision * sensitivity) / (precision + sensitivity), 4) if (precision + sensitivity) else 0.0\n",
    "\n",
    "                # Load training configuration from YAML\n",
    "                config_data = load_yaml_config(yaml_path, yaml_keys)\n",
    "                expected_data_path = os.path.join(data_base, sgkf, seed, fold_name)\n",
    "                yaml_data_path = config_data.pop('data', '')\n",
    "                config_data['data_path_match'] = (expected_data_path in (yaml_data_path or ''))\n",
    "\n",
    "                # Append full record\n",
    "                results.append({\n",
    "                    'sgkf': sgkf,\n",
    "                    'yolo_version': yolo,\n",
    "                    'seed': seed,\n",
    "                    'fold': fold_name,\n",
    "                    'TP': TP,\n",
    "                    'TN': TN,\n",
    "                    'FP': FP,\n",
    "                    'FN': FN,\n",
    "                    'accuracy': accuracy,\n",
    "                    'precision': precision,\n",
    "                    'sensitivity': sensitivity,\n",
    "                    'specificity': specificity,\n",
    "                    'f1_score': f1_score,\n",
    "                    'roc_auc': round(float(roc_auc), 4),\n",
    "                    **config_data\n",
    "                })\n",
    "\n",
    "        # Save summary CSV with descriptive name\n",
    "        csv_name = f\"test-{sgkf}-{yolo}.csv\"\n",
    "        output_path = os.path.join(base_run_dir, model_base, csv_name)\n",
    "        df = pd.DataFrame(results)\n",
    "        drop_columns = ['auto_augment']\n",
    "        df.drop(columns=[col for col in drop_columns if col in df.columns], inplace=True)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"\\nüìÜ Output saved to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
